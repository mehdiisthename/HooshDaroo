<div align="center">

<img src="logo/hooshdaroo.png" alt="HooshDaroo Logo" width="180"/>

# ğŸ’Š HooshDaroo (Ù‡ÙˆØ´ Ø¯Ø§Ø±Ùˆ)

### AI-Powered Persian Pharmaceutical Assistant

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.x-red?logo=streamlit)](https://streamlit.io/)
[![Neo4j](https://img.shields.io/badge/Neo4j-Graph%20DB-brightgreen?logo=neo4j)](https://neo4j.com/)
[![FAISS](https://img.shields.io/badge/FAISS-Vector%20DB-orange)](https://github.com/facebookresearch/faiss)
[![Ollama](https://img.shields.io/badge/Ollama-Gemma3%3A4b-lightgrey?logo=ollama)](https://ollama.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**HooshDaroo** is a bilingual (Persian/English) pharmaceutical chatbot that combines Retrieval-Augmented Generation (RAG) and Graph RAG over a pharmaceutical knowledge graph to deliver accurate, traceable, and evidence-backed answers to drug-related questions â€” powered entirely by local LLMs.

> ğŸ† Developed as the final capstone project for the **Hamrahe Aval (MCI) AI Bootcamp** â€” February 2026.

</div>

---

## âœ¨ Features

- ğŸ” **Hybrid Retrieval** â€” Combines BM25 sparse search and FAISS dense semantic search for robust context retrieval
- ğŸ•¸ï¸ **Graph RAG** â€” Queries a Neo4j pharmaceutical knowledge graph using LLM-extracted entities and structured Cypher queries
- ğŸ§  **LLM-Based Entity Extraction** â€” Recognizes drugs, conditions, adverse effects, drug classes, populations, and more from user queries
- ğŸŒ **Bilingual Support** â€” Handles questions in both Persian (Farsi) and English; always responds in fluent Persian
- ğŸ’¬ **Multi-Session Chat Management** â€” Create, name, and switch between multiple conversations with automatic summarization
- ğŸ“– **Evidence-Backed Answers** â€” Every answer is grounded in retrieved context from the knowledge base; no hallucinated facts
- ğŸƒ **Fully Local Inference** â€” Answer generation via [Ollama](https://ollama.com/) + `gemma3:4b`, no external LLM API calls needed for generation
- ğŸ“Š **LLM-as-a-Judge Evaluation** â€” Built-in evaluation pipeline to benchmark answer quality
- ğŸ¨ **Custom Dark UI** â€” Clean, responsive Streamlit interface with RTL Persian text support

---

## ğŸ—ï¸ System Architecture

HooshDaroo uses a **dual-retrieval pipeline** that runs both a vector-based RAG and a knowledge-graph-based GraphRAG in parallel, fusing their contexts before sending to the generator LLM.

```
User Query (Persian/English)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Query Analysis Layer                        â”‚
â”‚   Entity Extractor (AvalAI LLM)  â”‚  Persian Text Normalizer (hazm)â”‚
â”‚   Entities: Drug, Condition,     â”‚  Intent Classification:        â”‚
â”‚   AdverseEffect, DrugClass, ...  â”‚  INDICATION, INTERACTION, ...  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     RAG Pipeline   â”‚    â”‚   Graph RAG Pipeline   â”‚
          â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
          â”‚  BM25 (sparse)   â”‚    â”‚  Entity Linking         â”‚
          â”‚       +          â”‚    â”‚  (exact + fuzzy match)  â”‚
          â”‚  FAISS (dense)   â”‚    â”‚  â†“                      â”‚
          â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚    â”‚  Neo4j Cypher Queries   â”‚
          â”‚  Hybrid Fusion   â”‚    â”‚  (Indication, Interactionâ”‚
          â”‚  (alpha=0.5)     â”‚    â”‚   AdverseEffect, ...)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Generation Layer         â”‚
                    â”‚   Ollama + gemma3:4b (local) â”‚
                    â”‚   Streaming response         â”‚
                    â”‚   Persian output + sources   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
HooshDaroo/
â”œâ”€â”€ app.py                  # Main Streamlit web application
â”œâ”€â”€ answer.py               # Orchestrates RAG + GraphRAG + LLM generation
â”œâ”€â”€ rag.py                  # Hybrid BM25 + FAISS retrieval pipeline
â”œâ”€â”€ graphrag.py             # Full Graph RAG pipeline (entity linking, Cypher queries)
â”œâ”€â”€ entity_extractor.py     # LLM-based NER & intent classification
â”œâ”€â”€ chat.py                 # Multi-session chat management & summarization
â”œâ”€â”€ prompts.py              # System and summarization prompts
â”œâ”€â”€ evaluation.py           # LLM-as-a-Judge evaluation pipeline
â”œâ”€â”€ utils.py                # Shared utilities (token counting, ID generation)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ file.env                # Environment variable template (rename to .env)
â”œâ”€â”€ css/
â”‚   â””â”€â”€ styles.css          # Custom Streamlit styles
â”œâ”€â”€ logo/
â”‚   â””â”€â”€ hooshdaroo.png      # Application logo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ rag_chunks_v5.json  # Preprocessed pharmaceutical document chunks
â”œâ”€â”€ chats/                  # Persisted chat sessions (auto-created)
â”œâ”€â”€ graph_refs/             # Saved GraphRAG query results (auto-created)
â””â”€â”€ test/
    â”œâ”€â”€ questions.json       # Evaluation question set
    â””â”€â”€ results_1.json       # Evaluation results output
```

---

## âš™ï¸ Tech Stack

| Component | Technology |
|---|---|
| **Frontend** | Streamlit |
| **Vector Database** | FAISS (runtime) |
| **Knowledge Graph** | Neo4j |
| **Embedding Model** | `QWEN3-Embedding-0.6B` (via SentenceTransformers) |
| **Local LLM (Generation)** | `gemma3:4b` via Ollama |
| **LLM API (Entity Extraction)** | AvalAI (OpenAI-compatible) |
| **Sparse Retrieval** | BM25 via `rank_bm25` |
| **Persian NLP** | `hazm` (normalization, tokenization) |
| **Fuzzy Matching** | `rapidfuzz` |
| **Token Counting** | `tiktoken` (`cl100k_base`) |

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- [Ollama](https://ollama.com/) installed and running
- [Neo4j](https://neo4j.com/download/) instance (local or cloud)
- A GPU is recommended for embedding inference (CUDA)

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/HooshDaroo.git
cd HooshDaroo
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Pull the Local LLM

```bash
ollama pull gemma3:4b
```

### 4. Configure Environment Variables

Copy the template and fill in your settings:

```bash
cp file.env .env
```

Then edit `.env`:

| Variable | Description | Default |
|---|---|---|
| `EMBEDDING_MODEL` | Path or HuggingFace name for the embedding model | `QWEN/QWEN3-Embedding-0.6B` |
| `EMBEDDING_DEVICE` | Device for embedding inference | `cuda` |
| `NEO4J_URI` | Neo4j connection URI | `bolt://localhost:7687` |
| `NEO4J_USER` | Neo4j username | `neo4j` |
| `NEO4J_PASSWORD` | Neo4j password | â€” |
| `VECTOR_INDEX_NAME` | Neo4j vector index name | `chunk_embedding_index` |
| `FAISS_URI` | Path to the FAISS index file | â€” |
| `FAISS_METADATA` | Path to the FAISS metadata pickle file | â€” |
| `MILVUS_URI` | Milvus server URI (for indexing step only) | â€” |
| `COLLECTION_NAME` | Milvus collection name | â€” |
| `AVALAI_API_KEY` | AvalAI API key (for entity extraction) | â€” |
| `AVALAI_BASE_URL` | AvalAI base URL | `https://api.avalai.ir/v1` |
| `AVALAI_LLM_MODEL` | Model for entity extraction | `gpt-4o-mini` |
| `AVALAI_REASONING_EFFORT` | Reasoning intensity | `minimal` |

### 5. Run the Application

```bash
python -m streamlit run app.py
```

The app will open automatically in your browser at `http://localhost:8501`.

---

## ğŸ§© Module Details

### `rag.py` â€” Hybrid Retrieval
Implements a **hybrid BM25 + FAISS retrieval** strategy over pharmaceutical text chunks. At query time, BM25 sparse scores and FAISS dense cosine-similarity scores are each normalized and linearly fused:

```
final_score = Î± Ã— bm25_score + (1 âˆ’ Î±) Ã— dense_score
```

The default `Î± = 0.5` gives equal weight to both methods. Persian text is normalized before BM25 tokenization using character-level substitutions to handle Farsi script variations.

---

### `graphrag.py` â€” Graph RAG Pipeline
The most sophisticated module. It performs:

1. **Persian Text Normalization** using `hazm`
2. **LLM Entity Extraction** â€” calls `entity_extractor.py` to identify entities (drugs, conditions, interactions, etc.) and classify query intents
3. **Entity Linking** â€” matches extracted mentions to nodes in Neo4j via exact lookup â†’ fuzzy matching (`rapidfuzz`) â†’ semantic embedding similarity
4. **Cypher Query Routing** â€” routes to specialized Cypher queries based on detected intent:

| Intent | Description |
|---|---|
| `INDICATION` | What is this drug used for? |
| `ADVERSE_EFFECT` | What are the side effects? |
| `INTERACTION` | Does this drug interact with X? |
| `CONTRAINDICATION` | When should this drug NOT be used? |
| `CAUTION` | Special warnings and precautions |
| `COMPARISON` | Compare two drugs |
| `GENERAL_INFO` | General drug information |
| `POPULATION_SPECIFIC` | Use in pregnancy, children, elderly, etc. |
| `ASSOCIATION` | Drug-disease associations |
| `CAUSE` | Drug-induced conditions |

---

### `entity_extractor.py` â€” NER & Intent Classification
Uses an OpenAI-compatible LLM API (AvalAI) with **structured JSON output** (strict schema) to extract:
- **Entity types:** `drug`, `condition`, `adverse_effect`, `drug_class`, `interaction_agent`, `population`, `context`, `chemical`
- **Detected language:** `fa`, `en`, `mixed`
- **Query intents:** one or more from the 10 allowed intent classes

Includes up to 3 retry attempts for robust extraction.

---

### `chat.py` â€” Conversation Management
Manages persistent, named chat sessions stored as JSON files. Key features:
- **Automatic summarization** â€” when token count exceeds `MAX_TOKENS` (8192), older messages are summarized by `gemma3:4b` locally via Ollama and stored as `highlights`
- **Multi-session** â€” create, rename, and switch between independent conversations
- **Token tracking** â€” per-message token counting using `tiktoken`

---

### `answer.py` â€” Generation Orchestrator
Ties everything together:
1. Runs `hybrid_retrieve()` from `rag.py`
2. Runs `graph_rag.execute()` from `graphrag.py`
3. Formats a structured prompt with both context blocks and conversation history
4. Streams the response from `gemma3:4b` via Ollama
5. Saves GraphRAG query results as JSON references for traceability

---

### `evaluation.py` â€” Evaluation Pipeline
Runs a batch evaluation over a predefined test set (`test/questions.json`), collecting:
- The generated answer
- The RAG context used
- The GraphRAG context used

Results are saved to `test/results_1.json` were fed to an LLM-as-a-Judge scorer.

---

## ğŸ“Š Results & Evaluation

HooshDaroo was evaluated using an **LLM-as-a-Judge** framework, comparing three retrieval configurations to measure the impact of each retrieval strategy on answer quality.

### Evaluation Setup

Each sample in the test set was stored as a JSON record with four fields: the user question (`question`), context retrieved by plain RAG (`rag_context`), context retrieved by GraphRAG (`graph_rag_context`), and the final generated answer (`answer`). Three retrieval configurations were evaluated side-by-side:

| Configuration | Description |
|---|---|
| `rag_only` | Only the FAISS hybrid vector retrieval context |
| `graph_rag_only` | Only the Neo4j knowledge graph context |
| `both_combined` | Both RAG and GraphRAG contexts fused (production mode) |

A fixed evaluation prompt was sent to **GPT-5.1** (via OpenAI API) as the judge model. For each sample, the judge independently scored two criteria on a 1â€“5 scale:

- **Groundedness** â€” does the answer faithfully rely on the retrieved context, or does it generate unsupported claims?
- **Correctness** â€” is the answer factually accurate and responsive to the user's question?

### Scores

| Configuration | Groundedness (/ 5) | Correctness (/ 5) |
|---|---|---|
| RAG only | 3.88 | 4.24 |
| GraphRAG only | 3.94 | 4.27 |
| **Both combined** | **4.18** | **4.27** |

The combined approach yielded the highest Groundedness score (+0.30 over RAG-only), confirming that the knowledge graph meaningfully reduces unsupported generation. Correctness remained consistently high across all three conditions, reflecting the quality of the system prompt and the constraint that the model must only answer from given context.

### Acceptance Rate

Using a pass threshold of **Groundedness â‰¥ 4 AND Correctness â‰¥ 4**, the acceptance rates were:

| Configuration | Acceptance Rate |
|---|---|
| RAG only | 66.7% |
| GraphRAG only | 66.7% |
| **Both combined** | **75.8%** |

The dual-retrieval production mode lifted the acceptance rate by **9.1 percentage points** over either standalone method, validating the complementary nature of vector and graph retrieval.

### Error Analysis

Failures in the `both_combined` condition were categorized into four error types:

- **`INCORRECT_FACT`** â€” the answer contained a factual error not supported by context
- **`OMISSION`** â€” relevant information present in the context was not included in the answer
- **`OVERCONFIDENT`** â€” the answer stated uncertain information with unwarranted confidence
- **`NON_ANSWER`** â€” the model declined to answer or gave a deflection when context was sufficient

A safety check for **`DANGEROUS`** responses (medically harmful outputs) was also part of the evaluation prompt. No dangerous responses were flagged in the combined configuration.

### Limitations

The evaluation has several acknowledged limitations:

- **Generator model constraints:** `gemma3:4b` is a low-parameter, general-purpose model. In some scenarios it may produce hallucinations or spelling/grammatical errors in Persian output. Fine-tuning with LoRA on pharmaceutical Persian data is a planned improvement.
- **Judge model bias:** GPT-5.1 was used as the sole judge. A more robust evaluation would use multiple independent judges or human annotators.
- **End-to-end coverage:** The current evaluation assesses the final answer quality but does not independently benchmark retrieval recall, entity linking accuracy, or GraphRAG Cypher query coverage.
- **Dataset scope:** The test set reflects the coverage of the current knowledge base, which is limited in breadth. A larger and more diverse pharmaceutical dataset would enable more representative evaluation.

---

## ğŸ’¡ Key Design Decisions

- **Dual retrieval over single retrieval:** Vector search excels at semantic similarity while the knowledge graph handles structured relational lookups (e.g., "all drugs that interact with warfarin"). Using both maximizes coverage.
- **Local LLM for generation:** `gemma3:4b` via Ollama ensures full data privacy and zero generation API costs, while AvalAI is only used for the lightweight entity-extraction step.
- **Evidence-grounded answers only:** The system prompt strictly prohibits the model from answering outside the retrieved context, ensuring every response is traceable and hallucination-resistant.
- **Persian-first design:** Custom normalization, RTL UI layout, and a warm conversational tone modeled on a pharmacist â€” not a textbook â€” make the chatbot accessible to everyday Persian speakers.

---

## ğŸ”® Roadmap

- [ ] **Question classifier** â€” a fine-tuned lightweight classifier to pre-categorize user queries before retrieval
- [ ] **Domain fine-tuning** â€” fine-tune `Gemma3-4B` on medical Persian QA datasets
- [ ] **Web search integration** â€” augment knowledge base with live searches on trusted pharmaceutical sources
- [ ] **Richer dataset** â€” expand the knowledge graph and vector store with higher-quality, more comprehensive pharmaceutical data

---

## ğŸ‘¥ Team

| Name | Role |
|---|---|
| Mohammad Mahdi Qanbari | Developer |
| Sina Mahallati | Developer |
| Armita Ghorbani | Developer |
| Alireza Babazade | Developer |

---

## âš ï¸ Disclaimer

HooshDaroo is an **experimental research project** intended for educational purposes only. It is **not a substitute for professional medical or pharmaceutical advice**. Always consult a licensed pharmacist or physician before making any medication decisions.

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

<div align="center">
Made with â¤ï¸ and â˜• â€” February 2026
</div>
